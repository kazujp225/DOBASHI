"""YouTubeå‹•ç”»ã¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’åé›†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import json
from typing import List, Dict, Optional
from datetime import datetime
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


class YouTubeCollector:
    """YouTube Data API v3ã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã¨ã‚³ãƒ¡ãƒ³ãƒˆã‚’åé›†"""

    def __init__(self, api_key: str):
        """
        åˆæœŸåŒ–

        Args:
            api_key: YouTube Data API v3ã®APIã‚­ãƒ¼
        """
        self.api_key = api_key
        self.youtube = build('youtube', 'v3', developerKey=api_key)

    def get_channel_videos(
        self,
        channel_id: str,
        max_results: int = 50,
        published_after: Optional[str] = None
    ) -> List[Dict]:
        """
        ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰å‹•ç”»ä¸€è¦§ã‚’å–å¾—

        Args:
            channel_id: YouTubeãƒãƒ£ãƒ³ãƒãƒ«ID
            max_results: å–å¾—ã™ã‚‹å‹•ç”»ã®æœ€å¤§æ•°
            published_after: ã“ã®æ—¥æ™‚ä»¥é™ã®å‹•ç”»ã®ã¿å–å¾— (ISO 8601å½¢å¼)

        Returns:
            å‹•ç”»æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        videos = []

        try:
            # ãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å†ç”Ÿãƒªã‚¹ãƒˆIDã‚’å–å¾—
            channel_response = self.youtube.channels().list(
                part='contentDetails',
                id=channel_id
            ).execute()

            if not channel_response['items']:
                return videos

            uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']

            # å†ç”Ÿãƒªã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã‚’å–å¾—
            next_page_token = None

            while len(videos) < max_results:
                playlist_request = self.youtube.playlistItems().list(
                    part='snippet,contentDetails',
                    playlistId=uploads_playlist_id,
                    maxResults=min(50, max_results - len(videos)),
                    pageToken=next_page_token
                )

                playlist_response = playlist_request.execute()

                for item in playlist_response['items']:
                    video_id = item['contentDetails']['videoId']
                    published_at = item['snippet']['publishedAt']

                    # å…¬é–‹æ—¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if published_after and published_at < published_after:
                        continue

                    # å‹•ç”»ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
                    video_details = self.get_video_details(video_id)
                    if video_details:
                        videos.append(video_details)

                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break

            return videos

        except HttpError as e:
            print(f"YouTube API Error: {e}")
            return videos

    def get_video_details(self, video_id: str) -> Optional[Dict]:
        """
        å‹•ç”»ã®è©³ç´°æƒ…å ±ã‚’å–å¾—

        Args:
            video_id: YouTubeå‹•ç”»ID

        Returns:
            å‹•ç”»è©³ç´°æƒ…å ±ã®è¾æ›¸
        """
        try:
            response = self.youtube.videos().list(
                part='snippet,statistics',
                id=video_id
            ).execute()

            if not response['items']:
                return None

            item = response['items'][0]
            snippet = item['snippet']
            statistics = item['statistics']

            return {
                'video_id': video_id,
                'title': snippet['title'],
                'description': snippet['description'],
                'published_at': snippet['publishedAt'],
                'channel_id': snippet['channelId'],
                'channel_title': snippet['channelTitle'],
                'view_count': int(statistics.get('viewCount', 0)),
                'like_count': int(statistics.get('likeCount', 0)),
                'comment_count': int(statistics.get('commentCount', 0)),
                'thumbnail_url': snippet['thumbnails']['high']['url']
            }

        except HttpError as e:
            print(f"Error getting video details for {video_id}: {e}")
            return None

    def get_video_comments(
        self,
        video_id: str,
        max_results: Optional[int] = None,
        include_replies: bool = True,
        order: str = 'time',
        progress_callback=None
    ) -> List[Dict]:
        """
        å‹•ç”»ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—

        Args:
            video_id: YouTubeå‹•ç”»ID
            max_results: å–å¾—ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã®æœ€å¤§æ•°ï¼ˆNoneã®å ´åˆã¯å…¨ã¦å–å¾—ï¼‰
            include_replies: è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
            order: å–å¾—é †åº ('time': æ–°ã—ã„é †, 'relevance': é–¢é€£æ€§é †)
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•° callback(current, total_fetched)

        Returns:
            ã‚³ãƒ¡ãƒ³ãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        comments = []
        max_retries = 5  # 3â†’5ã«å¢—ã‚„ã™
        retry_delay = 3  # 2â†’3ç§’ã«å¢—ã‚„ã™

        try:
            next_page_token = None
            total_fetched = 0

            page_count = 0
            while True:
                page_count += 1

                # max_resultsãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãã®æ•°ã¾ã§å–å¾—
                if max_results is not None and len(comments) >= max_results:
                    break

                # 1å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å–å¾—ã™ã‚‹ä»¶æ•°ã‚’æ±ºå®š
                if max_results is None:
                    page_size = 100  # æœ€å¤§å€¤
                else:
                    page_size = min(100, max_results - len(comments))

                print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page_count}: {len(comments)}ä»¶å–å¾—æ¸ˆã¿...")

                # ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯
                retry_count = 0
                while retry_count < max_retries:
                    try:
                        request = self.youtube.commentThreads().list(
                            part='snippet,replies',
                            videoId=video_id,
                            maxResults=page_size,
                            pageToken=next_page_token,
                            textFormat='plainText',
                            order=order
                        )

                        response = request.execute()
                        break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

                    except HttpError as e:
                        retry_count += 1
                        error_detail = str(e)

                        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’è¡¨ç¤º
                        if hasattr(e, 'resp') and hasattr(e.resp, 'status'):
                            status_code = e.resp.status
                            print(f"âš ï¸ API Error {status_code} (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{max_retries}): {error_detail}")
                        else:
                            print(f"âš ï¸ API Error (ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{max_retries}): {error_detail}")

                        if retry_count >= max_retries:
                            print(f"âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•° ({max_retries}) ã«é”ã—ã¾ã—ãŸ")
                            raise  # æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ãŸã‚‰ä¾‹å¤–ã‚’æŠ•ã’ã‚‹

                        import time
                        wait_time = retry_delay * retry_count  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                        print(f"â±ï¸  {wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                        time.sleep(wait_time)

                # ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
                for item in response['items']:
                    top_comment = item['snippet']['topLevelComment']['snippet']

                    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ
                    comments.append({
                        'comment_id': item['snippet']['topLevelComment']['id'],
                        'video_id': video_id,
                        'author': top_comment['authorDisplayName'],
                        'author_channel_id': top_comment.get('authorChannelId', {}).get('value', ''),
                        'text': top_comment['textDisplay'],
                        'like_count': top_comment['likeCount'],
                        'published_at': top_comment['publishedAt'],
                        'updated_at': top_comment['updatedAt'],
                        'is_reply': False,
                        'parent_id': None
                    })

                    total_fetched += 1

                    # è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã‚‹å ´åˆ
                    if include_replies and 'replies' in item:
                        for reply in item['replies']['comments']:
                            reply_snippet = reply['snippet']

                            comments.append({
                                'comment_id': reply['id'],
                                'video_id': video_id,
                                'author': reply_snippet['authorDisplayName'],
                                'author_channel_id': reply_snippet.get('authorChannelId', {}).get('value', ''),
                                'text': reply_snippet['textDisplay'],
                                'like_count': reply_snippet['likeCount'],
                                'published_at': reply_snippet['publishedAt'],
                                'updated_at': reply_snippet['updatedAt'],
                                'is_reply': True,
                                'parent_id': reply_snippet['parentId']
                            })

                            total_fetched += 1

                    # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if progress_callback:
                        progress_callback(len(comments), total_fetched)

                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                next_page_token = response.get('nextPageToken')
                if not next_page_token:
                    print(f"âœ… å…¨ãƒšãƒ¼ã‚¸å–å¾—å®Œäº†ï¼ˆãƒšãƒ¼ã‚¸æ•°: {page_count}ï¼‰")
                    break  # ã“ã‚Œä»¥ä¸Šãƒšãƒ¼ã‚¸ãŒãªã„

            print(f"ğŸ‰ å–å¾—å®Œäº†: {len(comments)}ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆè¿”ä¿¡å«ã‚€ï¼‰")
            print(f"   ğŸ“Š å–å¾—ãƒšãƒ¼ã‚¸æ•°: {page_count}ãƒšãƒ¼ã‚¸")
            print(f"   ğŸ“ ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ + è¿”ä¿¡: {total_fetched}ä»¶")
            return comments

        except HttpError as e:
            error_reason = None
            if hasattr(e, 'resp') and hasattr(e.resp, 'status'):
                status_code = e.resp.status
                if status_code == 403:
                    if 'commentsDisabled' in str(e):
                        error_reason = "ã“ã®å‹•ç”»ã¯ã‚³ãƒ¡ãƒ³ãƒˆãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™"
                    elif 'quotaExceeded' in str(e):
                        error_reason = "YouTube API ã®ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸï¼ˆ1æ—¥ã®ä¸Šé™ï¼‰"
                    else:
                        error_reason = "APIã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚¨ãƒ©ãƒ¼"
                elif status_code == 404:
                    error_reason = "å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

            if error_reason:
                print(f"âŒ Error getting comments for video {video_id}: {error_reason}")
            else:
                print(f"âŒ Error getting comments for video {video_id}: {e}")

            # é€”ä¸­ã¾ã§å–å¾—ã§ãã¦ã„ã‚Œã°ãã‚Œã‚’è¿”ã™ï¼ˆãƒ­ã‚°ã«è­¦å‘Šã‚’å‡ºã™ï¼‰
            if comments:
                print(f"âš ï¸ è­¦å‘Š: {len(comments)}ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸãŒã€å…¨ä»¶å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                print(f"   ç†ç”±: {error_reason or str(e)}")

            return comments

    def save_to_json(self, data: Dict, filename: str):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

        Args:
            data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


# ä½¿ç”¨ä¾‹
if __name__ == '__main__':
    # APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ã‚’æ¨å¥¨
    import os

    api_key = os.environ.get('YOUTUBE_API_KEY', '')
    if not api_key:
        print("ç’°å¢ƒå¤‰æ•° YOUTUBE_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        exit(1)

    collector = YouTubeCollector(api_key)

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆä»¤å’Œã®è™ã®ãƒãƒ£ãƒ³ãƒãƒ«IDï¼‰
    # å®Ÿéš›ã®ãƒãƒ£ãƒ³ãƒãƒ«IDã«ç½®ãæ›ãˆã¦ãã ã•ã„
    channel_id = 'YOUR_CHANNEL_ID'

    # å‹•ç”»ã‚’å–å¾—
    print("å‹•ç”»ã‚’å–å¾—ä¸­...")
    videos = collector.get_channel_videos(channel_id, max_results=5)
    print(f"{len(videos)}ä»¶ã®å‹•ç”»ã‚’å–å¾—ã—ã¾ã—ãŸ")

    # æœ€åˆã®å‹•ç”»ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    if videos:
        video_id = videos[0]['video_id']
        print(f"\nå‹•ç”» '{videos[0]['title']}' ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ä¸­...")
        comments = collector.get_video_comments(video_id, max_results=100)
        print(f"{len(comments)}ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
