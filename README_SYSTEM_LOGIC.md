# ğŸ§  ä»¤å’Œã®è™åˆ†æã‚·ã‚¹ãƒ†ãƒ  - ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°

## ğŸ“ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ (React)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚Dashboard â”‚ â”‚Analysis  â”‚ â”‚Sentiment â”‚ â”‚Reports   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    REST API / WebSocket
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ (FastAPI)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  APIãƒ¬ã‚¤ãƒ¤ãƒ¼                            â”‚  â”‚
â”‚  â”‚  - /api/v1/videos    - /api/v1/sentiment             â”‚  â”‚
â”‚  â”‚  - /api/v1/tigers    - /api/v1/wordcloud            â”‚  â”‚
â”‚  â”‚  - /api/v1/analysis  - /api/v1/comparison           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å±¤                      â”‚  â”‚
â”‚  â”‚  - CommentAnalyzer   - SentimentAnalyzer            â”‚  â”‚
â”‚  â”‚  - TigerManager      - WordCloudGenerator           â”‚  â”‚
â”‚  â”‚  - StatsAggregator   - ReportGenerator              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å±¤                        â”‚  â”‚
â”‚  â”‚  - SQLAlchemy ORM    - Redis Cache                  â”‚  â”‚
â”‚  â”‚  - Database Models   - YouTube API Client           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PostgreSQL  â”‚            â”‚    Redis     â”‚
        â”‚   Database   â”‚            â”‚    Cache     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¨ãƒ­ã‚¸ãƒƒã‚¯

### 1. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå‹•ç”»URLã‚’å…¥åŠ›] --> B[YouTube APIå‘¼ã³å‡ºã—]
    B --> C{å‹•ç”»æƒ…å ±å–å¾—}
    C -->|æˆåŠŸ| D[ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—é–‹å§‹]
    C -->|å¤±æ•—| E[ã‚¨ãƒ©ãƒ¼å‡¦ç†]
    D --> F[ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†]
    F --> G{å…¨ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—å®Œäº†?}
    G -->|No| F
    G -->|Yes| H[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜]
    H --> I[åé›†å®Œäº†é€šçŸ¥]
```

#### è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯ï¼š

1. **å‹•ç”»æƒ…å ±å–å¾—** (`collectors/youtube_collector.py`)
   ```python
   # YouTube APIã‹ã‚‰å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
   video_response = youtube.videos().list(
       part="snippet,statistics",
       id=video_id
   ).execute()
   ```

2. **ã‚³ãƒ¡ãƒ³ãƒˆåé›†**
   - ãƒšãƒ¼ã‚¸ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ãŸå†å¸°çš„å–å¾—
   - è¿”ä¿¡ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å«ã‚ã¦å®Œå…¨å–å¾—
   - APIã‚¯ã‚©ãƒ¼ã‚¿ç®¡ç†ï¼ˆ10,000 units/dayï¼‰
   - ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§3å›ï¼‰

3. **ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–**
   - UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
   - HTMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ãƒ‡ã‚³ãƒ¼ãƒ‰
   - æ”¹è¡Œãƒ»ç©ºç™½ã®çµ±ä¸€

### 2. ç¤¾é•·è¨€åŠåˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯

```mermaid
graph LR
    A[ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ] --> B[å‰å‡¦ç†]
    B --> C[ã‚¨ã‚¤ãƒªã‚¢ã‚¹ãƒãƒƒãƒãƒ³ã‚°]
    C --> D{ãƒãƒƒãƒç™ºè¦‹?}
    D -->|Yes| E[ç¤¾é•·IDç‰¹å®š]
    D -->|No| F[è¨€åŠãªã—]
    E --> G[ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—]
    G --> H[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜]
```

#### åˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š

```python
def analyze_comment(comment_text: str) -> List[TigerMention]:
    """
    ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ç¤¾é•·è¨€åŠã‚’åˆ¤å®šã™ã‚‹ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯
    """
    mentions = []
    normalized_text = normalize_text(comment_text)

    # 1. å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰
    for tiger in tigers:
        for alias in tiger.aliases:
            if alias.type == "primary":
                if exact_match(normalized_text, alias.name):
                    mentions.append(TigerMention(
                        tiger_id=tiger.id,
                        confidence=1.0,
                        match_type="exact"
                    ))

    # 2. éƒ¨åˆ†ä¸€è‡´ãƒã‚§ãƒƒã‚¯ï¼ˆå„ªå…ˆåº¦: ä¸­ï¼‰
    if not mentions:
        for tiger in tigers:
            for alias in tiger.aliases:
                if alias.type == "nickname":
                    if partial_match(normalized_text, alias.name):
                        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
                        if check_context(normalized_text, alias.name):
                            mentions.append(TigerMention(
                                tiger_id=tiger.id,
                                confidence=0.8,
                                match_type="partial"
                            ))

    # 3. æ›–æ˜§ãªè¡¨ç¾ã®å‡¦ç†ï¼ˆå„ªå…ˆåº¦: ä½ï¼‰
    if not mentions:
        if contains_ambiguous_reference(normalized_text):
            # æ–‡è„ˆã‹ã‚‰æ¨å®š
            tiger_id = infer_from_context(normalized_text, video_context)
            if tiger_id:
                mentions.append(TigerMention(
                    tiger_id=tiger_id,
                    confidence=0.6,
                    match_type="contextual"
                ))

    return mentions
```

#### ã‚¨ã‚¤ãƒªã‚¢ã‚¹å„ªå…ˆåº¦ï¼š

1. **æœ¬åå®Œå…¨å½¢** (æ—å°šå¼˜) - å„ªå…ˆåº¦: 100
2. **æ•¬ç§°ä»˜ãå§“** (æ—ç¤¾é•·) - å„ªå…ˆåº¦: 90
3. **ä¼šç¤¾åä»˜ã** (ãƒ¢ãƒ“ãƒªãƒ†ã‚£ãƒ¼ãƒ©ãƒ³ãƒ‰ã®æ—) - å„ªå…ˆåº¦: 85
4. **ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ** (FCç¤¾é•·) - å„ªå…ˆåº¦: 70
5. **å§“ã®ã¿** (æ—) - å„ªå…ˆåº¦: 50ï¼ˆæ–‡è„ˆãƒã‚§ãƒƒã‚¯å¿…é ˆï¼‰

### 3. æ„Ÿæƒ…åˆ†æãƒ­ã‚¸ãƒƒã‚¯

```mermaid
graph TD
    A[ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆ] --> B[å½¢æ…‹ç´ è§£æ]
    B --> C[æ„Ÿæƒ…è¾æ›¸ãƒãƒƒãƒãƒ³ã‚°]
    C --> D[çµµæ–‡å­—è§£æ]
    D --> E[å¦å®šè¡¨ç¾ãƒã‚§ãƒƒã‚¯]
    E --> F[å¼·èª¿è¡¨ç¾ãƒã‚§ãƒƒã‚¯]
    F --> G[ã‚¹ã‚³ã‚¢é›†è¨ˆ]
    G --> H{åˆ¤å®š}
    H -->|score > 0.3| I[ãƒã‚¸ãƒ†ã‚£ãƒ–]
    H -->|score < -0.3| J[ãƒã‚¬ãƒ†ã‚£ãƒ–]
    H -->|ãã®ä»–| K[ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«]
```

#### æ„Ÿæƒ…åˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼š

```python
class SentimentAnalyzer:
    def analyze(self, text: str) -> SentimentResult:
        score = 0.0

        # 1. è¾æ›¸ãƒ™ãƒ¼ã‚¹åˆ¤å®š
        for word in self.positive_words:
            if word in text:
                score += self.positive_weights[word]

        for word in self.negative_words:
            if word in text:
                score -= self.negative_weights[word]

        # 2. çµµæ–‡å­—åˆ¤å®š
        for emoji in extract_emojis(text):
            if emoji in self.positive_emojis:
                score += 0.5
            elif emoji in self.negative_emojis:
                score -= 0.5

        # 3. å¦å®šè¡¨ç¾ã®åè»¢
        if has_negation(text):
            score = -score * 0.8

        # 4. å¼·èª¿è¡¨ç¾ã®å¢—å¹…
        if has_emphasis(text):  # "ã™ã”ã", "ã¨ã¦ã‚‚", "ï¼ï¼"
            score = score * 1.5

        # 5. æœ€çµ‚åˆ¤å®š
        if score > 0.3:
            return SentimentResult(label="positive", score=score)
        elif score < -0.3:
            return SentimentResult(label="negative", score=score)
        else:
            return SentimentResult(label="neutral", score=score)
```

### 4. çµ±è¨ˆé›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯

#### Rate_totalï¼ˆçµ¶å¯¾çš„å­˜åœ¨æ„Ÿï¼‰ã®è¨ˆç®—ï¼š

```python
def calculate_rate_total(tiger_id: str, video_id: str) -> float:
    """
    å‹•ç”»å…¨ä½“ã«ãŠã‘ã‚‹ãã®ç¤¾é•·ã®å­˜åœ¨æ„Ÿã‚’è¨ˆç®—
    """
    # ãã®ç¤¾é•·ã«è¨€åŠã—ãŸã‚³ãƒ¡ãƒ³ãƒˆæ•°
    tiger_mentions = db.query(CommentTigerRelation)\
        .filter_by(tiger_id=tiger_id, video_id=video_id)\
        .count()

    # å‹•ç”»ã®ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°
    total_comments = db.query(Comment)\
        .filter_by(video_id=video_id)\
        .count()

    if total_comments == 0:
        return 0.0

    return (tiger_mentions / total_comments) * 100
```

#### Rate_entityï¼ˆç›¸å¯¾çš„ä¸»å½¹åº¦ï¼‰ã®è¨ˆç®—ï¼š

```python
def calculate_rate_entity(tiger_id: str, video_id: str) -> float:
    """
    ç¤¾é•·é–¢é€£ã‚³ãƒ¡ãƒ³ãƒˆå†…ã§ã®ãã®ç¤¾é•·ã®å‰²åˆã‚’è¨ˆç®—
    """
    # ãã®ç¤¾é•·ã«è¨€åŠã—ãŸã‚³ãƒ¡ãƒ³ãƒˆæ•°
    tiger_mentions = db.query(CommentTigerRelation)\
        .filter_by(tiger_id=tiger_id, video_id=video_id)\
        .count()

    # ç¤¾é•·ã«è¨€åŠã—ãŸå…¨ã‚³ãƒ¡ãƒ³ãƒˆæ•°ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼‰
    tiger_related_comments = db.query(CommentTigerRelation.comment_id)\
        .filter_by(video_id=video_id)\
        .distinct()\
        .count()

    if tiger_related_comments == 0:
        return 0.0

    return (tiger_mentions / tiger_related_comments) * 100
```

### 5. ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯

```python
def generate_wordcloud(comments: List[str]) -> Dict[str, int]:
    """
    ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰é »å‡ºå˜èªã‚’æŠ½å‡º
    """
    word_freq = {}

    for comment in comments:
        # 1. å½¢æ…‹ç´ è§£æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        words = simple_tokenize(comment)

        # 2. ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»
        words = [w for w in words if w not in STOP_WORDS]

        # 3. å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆåè©ãƒ»å‹•è©ãƒ»å½¢å®¹è©ã®ã¿ï¼‰
        words = filter_by_pos(words, ['åè©', 'å‹•è©', 'å½¢å®¹è©'])

        # 4. é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
        for word in words:
            if len(word) >= 2:  # 2æ–‡å­—ä»¥ä¸Š
                word_freq[word] = word_freq.get(word, 0) + 1

    # 5. TF-IDFé‡ã¿ä»˜ã‘ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if use_tfidf:
        word_freq = apply_tfidf_weights(word_freq, all_documents)

    # 6. ä¸Šä½Nä»¶ã‚’è¿”ã™
    return dict(sorted(word_freq.items(),
                      key=lambda x: x[1],
                      reverse=True)[:100])
```

### 6. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆWebSocketï¼‰

```python
class WebSocketManager:
    async def periodic_update(self):
        """
        10ç§’ã”ã¨ã«çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
        """
        while True:
            # 1. æœ€æ–°çµ±è¨ˆã‚’å–å¾—
            stats = await get_realtime_stats()

            # 2. å…¨æ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
            for connection in self.active_connections:
                await connection.send_json({
                    "type": "stats_update",
                    "data": {
                        "total_videos": stats.total_videos,
                        "total_comments": stats.total_comments,
                        "top_tigers": stats.top_tigers[:5],
                        "latest_analysis": stats.latest_analysis,
                        "timestamp": datetime.now().isoformat()
                    }
                })

            # 3. 10ç§’å¾…æ©Ÿ
            await asyncio.sleep(10)
```

### 7. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

```python
class CacheManager:
    def get_or_compute(self, key: str, compute_func, ttl: int = 300):
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°è¨ˆç®—ã—ã¦ä¿å­˜
        """
        # 1. Redisã‹ã‚‰å–å¾—è©¦è¡Œ
        if self.redis_client:
            cached = self.redis_client.get(key)
            if cached:
                return json.loads(cached)

        # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚ã¯è¨ˆç®—
        result = compute_func()

        # 3. çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        if self.redis_client:
            self.redis_client.setex(
                key,
                ttl,
                json.dumps(result, ensure_ascii=False)
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
            self.memory_cache[key] = {
                'data': result,
                'expires_at': time.time() + ttl
            }

        return result
```

### 8. æ¯”è¼ƒåˆ†æãƒ­ã‚¸ãƒƒã‚¯

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼š

```python
def calculate_performance_score(tiger_stats: TigerStats) -> float:
    """
    ç¤¾é•·ã®ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    """
    # é‡ã¿ä»˜ã‘ä¿‚æ•°
    weights = {
        'mentions': 0.3,      # è¨€åŠæ•°ã®é‡è¦åº¦
        'rate_total': 0.2,    # çµ¶å¯¾çš„å­˜åœ¨æ„Ÿ
        'rate_entity': 0.2,   # ç›¸å¯¾çš„ä¸»å½¹åº¦
        'sentiment': 0.2,     # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
        'growth': 0.1         # æˆé•·ç‡
    }

    # æ­£è¦åŒ–
    normalized = {
        'mentions': tiger_stats.total_mentions / max_mentions,
        'rate_total': tiger_stats.avg_rate_total / 100,
        'rate_entity': tiger_stats.avg_rate_entity / 100,
        'sentiment': (tiger_stats.sentiment_score + 100) / 200,
        'growth': (tiger_stats.growth_rate + 100) / 200
    }

    # åŠ é‡å¹³å‡
    score = sum(
        normalized[key] * weights[key]
        for key in weights
    )

    return score * 100  # 0-100ã‚¹ã‚±ãƒ¼ãƒ«
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚¸ãƒƒã‚¯

### JWTèªè¨¼ãƒ•ãƒ­ãƒ¼ï¼š

```python
def authenticate_user(username: str, password: str) -> Optional[User]:
    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¤œç´¢
    user = db.query(User).filter_by(username=username).first()
    if not user:
        return None

    # 2. ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼ï¼ˆbcryptï¼‰
    if not verify_password(password, user.hashed_password):
        return None

    # 3. JWTãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ
    payload = {
        "sub": user.id,
        "exp": datetime.utcnow() + timedelta(hours=24),
        "iat": datetime.utcnow()
    }
    token = jwt.encode(payload, SECRET_KEY, algorithm="HS256")

    return {"access_token": token, "token_type": "bearer"}
```

## ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼š

```sql
-- é »ç¹ã«æ¤œç´¢ã•ã‚Œã‚‹åˆ—ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_comments_video_id ON comments(video_id);
CREATE INDEX idx_comment_tiger_relations_tiger_id ON comment_tiger_relations(tiger_id);
CREATE INDEX idx_comment_tiger_relations_video_id ON comment_tiger_relations(video_id);
CREATE INDEX idx_video_tiger_stats_composite ON video_tiger_stats(video_id, tiger_id);
```

### 2. N+1å•é¡Œã®å›é¿ï¼š

```python
# âŒ æ‚ªã„ä¾‹ï¼šN+1å•é¡Œ
videos = db.query(Video).all()
for video in videos:
    # å„ãƒ“ãƒ‡ã‚ªã”ã¨ã«ã‚¯ã‚¨ãƒªç™ºè¡Œ
    stats = db.query(VideoTigerStats).filter_by(video_id=video.id).all()

# âœ… è‰¯ã„ä¾‹ï¼šEager Loading
videos = db.query(Video)\
    .options(joinedload(Video.tiger_stats))\
    .all()
```

### 3. ãƒãƒƒãƒå‡¦ç†ï¼š

```python
def batch_insert_comments(comments: List[Dict], batch_size: int = 1000):
    """
    å¤§é‡ã‚³ãƒ¡ãƒ³ãƒˆã®åŠ¹ç‡çš„ãªæŒ¿å…¥
    """
    for i in range(0, len(comments), batch_size):
        batch = comments[i:i + batch_size]
        db.bulk_insert_mappings(Comment, batch)
        db.commit()
```

## ğŸ“Š ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒªã‚«ãƒãƒªãƒ¼

### YouTube API ã‚¨ãƒ©ãƒ¼å‡¦ç†ï¼š

```python
def safe_api_call(api_func, max_retries=3):
    """
    APIã‚¨ãƒ©ãƒ¼ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
    """
    for attempt in range(max_retries):
        try:
            return api_func()
        except HttpError as e:
            if e.resp.status == 403:  # ã‚¯ã‚©ãƒ¼ã‚¿è¶…é
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt * 60  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    time.sleep(wait_time)
                else:
                    raise QuotaExceededException()
            elif e.resp.status == 404:  # å‹•ç”»ãŒè¦‹ã¤ã‹ã‚‰ãªã„
                raise VideoNotFoundException()
            else:
                raise
```

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿åŒæœŸæˆ¦ç•¥

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ï¼š

```python
def invalidate_related_caches(video_id: str):
    """
    é–¢é€£ã™ã‚‹ã™ã¹ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
    """
    patterns_to_delete = [
        f"video_stats:{video_id}",
        f"video_ranking:*",
        f"tiger_stats:*:{video_id}",
        f"wordcloud:{video_id}",
        f"sentiment:{video_id}"
    ]

    for pattern in patterns_to_delete:
        for key in redis_client.scan_iter(match=pattern):
            redis_client.delete(key)
```

## ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œï¼š

1. **ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹è¨­è¨ˆ**: ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã¯Redisã§ç®¡ç†
2. **ã‚­ãƒ¥ãƒ¼å‡¦ç†**: Celeryã«ã‚ˆã‚‹éåŒæœŸã‚¿ã‚¹ã‚¯å‡¦ç†ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
3. **ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼**: nginx/HAProxyã§ã®è² è·åˆ†æ•£
4. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: Read Replicaã®åˆ©ç”¨å¯èƒ½

### å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œï¼š

1. **ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°**: SQLAlchemy pool_sizeè¨­å®š
2. **ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–**: ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ä½¿ç”¨ã§å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†
3. **ä¸¦åˆ—å‡¦ç†**: asyncio/ThreadPoolExecutoræ´»ç”¨

---

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ä»¤å’Œã®è™åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®å†…éƒ¨ãƒ­ã‚¸ãƒƒã‚¯ã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚
å„æ©Ÿèƒ½ã®å®Ÿè£…è©³ç´°ã«ã¤ã„ã¦ã¯ã€å¯¾å¿œã™ã‚‹ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚